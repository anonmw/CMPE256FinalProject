{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/soc-redditHyperlinks-body.tsv', sep='\\t')\n",
    "df['NODE_ID'] = df['SOURCE_SUBREDDIT'] + '_' + df['TARGET_SUBREDDIT']\n",
    "df['TIMESTAMP'] =  pd.to_datetime(df['TIMESTAMP'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "      <th>NODE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>teamredditteams</td>\n",
       "      <td>1u4nrps</td>\n",
       "      <td>2013-12-31 16:39:58</td>\n",
       "      <td>1</td>\n",
       "      <td>345.0,298.0,0.75652173913,0.0173913043478,0.08...</td>\n",
       "      <td>leagueoflegends_teamredditteams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theredlion</td>\n",
       "      <td>soccer</td>\n",
       "      <td>1u4qkd</td>\n",
       "      <td>2013-12-31 18:18:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>101.0,98.0,0.742574257426,0.019801980198,0.049...</td>\n",
       "      <td>theredlion_soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inlandempire</td>\n",
       "      <td>bikela</td>\n",
       "      <td>1u4qlzs</td>\n",
       "      <td>2014-01-01 14:54:35</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0,85.0,0.752941176471,0.0235294117647,0.082...</td>\n",
       "      <td>inlandempire_bikela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nfl</td>\n",
       "      <td>cfb</td>\n",
       "      <td>1u4sjvs</td>\n",
       "      <td>2013-12-31 17:37:55</td>\n",
       "      <td>1</td>\n",
       "      <td>1124.0,949.0,0.772241992883,0.0017793594306,0....</td>\n",
       "      <td>nfl_cfb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>playmygame</td>\n",
       "      <td>gamedev</td>\n",
       "      <td>1u4w5ss</td>\n",
       "      <td>2014-01-01 02:51:13</td>\n",
       "      <td>1</td>\n",
       "      <td>715.0,622.0,0.777622377622,0.00699300699301,0....</td>\n",
       "      <td>playmygame_gamedev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SOURCE_SUBREDDIT TARGET_SUBREDDIT  POST_ID           TIMESTAMP  \\\n",
       "0  leagueoflegends  teamredditteams  1u4nrps 2013-12-31 16:39:58   \n",
       "1       theredlion           soccer   1u4qkd 2013-12-31 18:18:37   \n",
       "2     inlandempire           bikela  1u4qlzs 2014-01-01 14:54:35   \n",
       "3              nfl              cfb  1u4sjvs 2013-12-31 17:37:55   \n",
       "4       playmygame          gamedev  1u4w5ss 2014-01-01 02:51:13   \n",
       "\n",
       "   LINK_SENTIMENT                                         PROPERTIES  \\\n",
       "0               1  345.0,298.0,0.75652173913,0.0173913043478,0.08...   \n",
       "1              -1  101.0,98.0,0.742574257426,0.019801980198,0.049...   \n",
       "2               1  85.0,85.0,0.752941176471,0.0235294117647,0.082...   \n",
       "3               1  1124.0,949.0,0.772241992883,0.0017793594306,0....   \n",
       "4               1  715.0,622.0,0.777622377622,0.00699300699301,0....   \n",
       "\n",
       "                           NODE_ID  \n",
       "0  leagueoflegends_teamredditteams  \n",
       "1                theredlion_soccer  \n",
       "2              inlandempire_bikela  \n",
       "3                          nfl_cfb  \n",
       "4               playmygame_gamedev  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of links > number of unique posts meaning some posts have multiple hyperlinks\n",
    "- number of unique source to target subreddits << number of unique nodes\n",
    "- nodes = subreddits, edges = hyperlink, weight = number of posts that linked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique posts 259092\n"
     ]
    }
   ],
   "source": [
    "print ('number of unique posts {0}'.format(len(np.unique(df['POST_ID']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of links 286561\n"
     ]
    }
   ],
   "source": [
    "print ('number of links {0}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique node ids 137821\n"
     ]
    }
   ],
   "source": [
    "print ('number of unique node ids {0}'.format(len(np.unique(df['NODE_ID']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique subreddits 137820\n"
     ]
    }
   ],
   "source": [
    "print ('number of unique subreddits {0}'.format(len(np.unique(df['SOURCE_SUBREDDIT'] + df['TARGET_SUBREDDIT']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- about 3-years worth of hyperlink data collected from December 31st, 2013 to April 30th, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time range 2013-12-31 16:39:58 - 2017-04-30 16:58:21\n"
     ]
    }
   ],
   "source": [
    "print ('time range {0} - {1}'.format(df['TIMESTAMP'].min(), df['TIMESTAMP'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calculate edge weight - number of posts containing a hyperlink between two subreddits\n",
    "- most subreddits about 1-2 links between them, but some contain hundreds\n",
    "- some subreddits are much more popular than others\n",
    "- min = 1, max = 548, mean = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    137821.000000\n",
       "mean          2.079226\n",
       "std           5.495717\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           1.000000\n",
       "max         548.000000\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_df = df.groupby(['NODE_ID']).size().reset_index(name='weight')\n",
    "weighted_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len after grouping 137821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NODE_ID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>trendingsubreddits_changelog</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114896</th>\n",
       "      <td>streetfighter_sf4</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>buildapc_buildapcforme</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80234</th>\n",
       "      <td>mushroomkingdom_gamesale</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17348</th>\n",
       "      <td>bluejackets_bluejacketsgwg</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             NODE_ID  weight\n",
       "128037  trendingsubreddits_changelog     548\n",
       "114896             streetfighter_sf4     279\n",
       "19991         buildapc_buildapcforme     244\n",
       "80234       mushroomkingdom_gamesale     243\n",
       "17348     bluejackets_bluejacketsgwg     223"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('len after grouping {0}'.format(len(weighted_df)))\n",
    "weighted_df.sort_values(['weight'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NODE_ID</th>\n",
       "      <th>weight</th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145360</th>\n",
       "      <td>leagueoflegends_teamredditteams</td>\n",
       "      <td>39</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>teamredditteams</td>\n",
       "      <td>1u4nrps</td>\n",
       "      <td>2013-12-31 16:39:58</td>\n",
       "      <td>1</td>\n",
       "      <td>345.0,298.0,0.75652173913,0.0173913043478,0.08...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174067</th>\n",
       "      <td>nfl_cfb</td>\n",
       "      <td>14</td>\n",
       "      <td>nfl</td>\n",
       "      <td>cfb</td>\n",
       "      <td>1u4sjvs</td>\n",
       "      <td>2013-12-31 17:37:55</td>\n",
       "      <td>1</td>\n",
       "      <td>1124.0,949.0,0.772241992883,0.0017793594306,0....</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259858</th>\n",
       "      <td>theredlion_soccer</td>\n",
       "      <td>1</td>\n",
       "      <td>theredlion</td>\n",
       "      <td>soccer</td>\n",
       "      <td>1u4qkd</td>\n",
       "      <td>2013-12-31 18:18:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>101.0,98.0,0.742574257426,0.019801980198,0.049...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82626</th>\n",
       "      <td>dogemarket_dogecoin</td>\n",
       "      <td>71</td>\n",
       "      <td>dogemarket</td>\n",
       "      <td>dogecoin</td>\n",
       "      <td>1u4w7bs</td>\n",
       "      <td>2013-12-31 18:35:44</td>\n",
       "      <td>1</td>\n",
       "      <td>1328.0,1110.0,0.768825301205,0.0143072289157,0...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113100</th>\n",
       "      <td>gfycat_india</td>\n",
       "      <td>1</td>\n",
       "      <td>gfycat</td>\n",
       "      <td>india</td>\n",
       "      <td>1u5df2s</td>\n",
       "      <td>2013-12-31 22:27:50</td>\n",
       "      <td>1</td>\n",
       "      <td>2849.0,2467.0,0.704106704107,0.00737100737101,...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                NODE_ID  weight SOURCE_SUBREDDIT  \\\n",
       "145360  leagueoflegends_teamredditteams      39  leagueoflegends   \n",
       "174067                          nfl_cfb      14              nfl   \n",
       "259858                theredlion_soccer       1       theredlion   \n",
       "82626               dogemarket_dogecoin      71       dogemarket   \n",
       "113100                     gfycat_india       1           gfycat   \n",
       "\n",
       "       TARGET_SUBREDDIT  POST_ID           TIMESTAMP  LINK_SENTIMENT  \\\n",
       "145360  teamredditteams  1u4nrps 2013-12-31 16:39:58               1   \n",
       "174067              cfb  1u4sjvs 2013-12-31 17:37:55               1   \n",
       "259858           soccer   1u4qkd 2013-12-31 18:18:37              -1   \n",
       "82626          dogecoin  1u4w7bs 2013-12-31 18:35:44               1   \n",
       "113100            india  1u5df2s 2013-12-31 22:27:50               1   \n",
       "\n",
       "                                               PROPERTIES  YEAR  \n",
       "145360  345.0,298.0,0.75652173913,0.0173913043478,0.08...  2013  \n",
       "174067  1124.0,949.0,0.772241992883,0.0017793594306,0....  2013  \n",
       "259858  101.0,98.0,0.742574257426,0.019801980198,0.049...  2013  \n",
       "82626   1328.0,1110.0,0.768825301205,0.0143072289157,0...  2013  \n",
       "113100  2849.0,2467.0,0.704106704107,0.00737100737101,...  2013  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(weighted_df, df, how='inner').sort_values(['TIMESTAMP'], ascending=True)\n",
    "print (len(merged_df))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to split train and test data?\n",
    "- By timestamp? train = links created from 2013 - 2016, test = links created in 2017\n",
    "- Disregard when link was created - train = 80% of links and test = 20% (randomly removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directed, weighted graph from links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.from_pandas_edgelist(merged_df,\n",
    "                            \"SOURCE_SUBREDDIT\",\n",
    "                            \"TARGET_SUBREDDIT\",\n",
    "                            [\"POST_ID\", \"TIMESTAMP\", \"LINK_SENTIMENT\", \"weight\"],\n",
    "                           create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove nodes with less than 5 connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph size before filter 124330\n",
      "graph size after filter 42669\n",
      "Graph with 1682 nodes and 42669 edges\n"
     ]
    }
   ],
   "source": [
    "print ('graph size before filter {0}'.format(G.size()))\n",
    "remove = [node for node, degree in dict(G.degree()).items() if degree <= 25]\n",
    "G.remove_nodes_from(remove)\n",
    "print ('graph size after filter {0}'.format(G.size()))\n",
    "print (G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly sample edges to remove from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size 42669, sample size 8533.800000000001\n",
      "sample from test set [('askhistorians', 'askpsychology'), ('kendricklamar', 'runthejewels'), ('nofap', 'nudism'), ('randomactsofgaming', 'uncensorednews'), ('lakers', 'pacers'), ('newjersey', 'blog'), ('relationships', 'nursing'), ('copypasta', 'psychonaut'), ('sex', 'bisexual'), ('theredpill', 'csshelp')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/3y2s7qxs3nl50c84jp8_80v00000gn/T/ipykernel_4793/282736771.py:4: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  test = random.sample(G.edges(), int(sample_size))\n"
     ]
    }
   ],
   "source": [
    "total_size = len(G.edges())\n",
    "sample_size = 0.2 * total_size\n",
    "print ('total size {0}, sample size {1}'.format(total_size, sample_size))\n",
    "test = random.sample(G.edges(), int(sample_size))\n",
    "print ('sample from test set {0}'.format(test[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of original 42669\n",
      "size of train 34136\n"
     ]
    }
   ],
   "source": [
    "print ('size of original {0}'.format(G.size()))\n",
    "G.remove_edges_from(test)\n",
    "print ('size of train {0}'.format(G.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect communities in training set\n",
    "- Resolution: 1, 20 communities, max size = 358\n",
    "- Resolution: 5, 103 communities, max size = 53\n",
    "- Resolution: 3, 57 communities, max size = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "communities = list(greedy_modularity_communities(G, weight='weight', resolution=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57 communities\n",
      "Largest community has 106 nodes\n",
      "Smallest community has 1 nodes\n"
     ]
    }
   ],
   "source": [
    "print ('Found {0} communities'.format(len(communities)))\n",
    "print ('Largest community has {0} nodes'.format(len(communities[0])))\n",
    "print ('Smallest community has {0} nodes'.format(len(communities[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes across all communities = 1682\n",
      "Largest community accounted for 6.302021403091558% of nodes\n",
      "Smallest community accounted for 0.05945303210463733% of nodes\n",
      "Midsize community accounted for 1.7241379310344827% of nodes\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for community in communities:\n",
    "    total += len(community)\n",
    "\n",
    "print ('Total nodes across all communities = {0}'.format(total))\n",
    "print ('Largest community accounted for {0}% of nodes'.format(len(communities[0]) / total * 100))\n",
    "print ('Smallest community accounted for {0}% of nodes'.format(len(communities[-1]) / total * 100))\n",
    "print ('Midsize community accounted for {0}% of nodes'.format(len(communities[20]) / total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect a few communities manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Community #25 (size = 29): religion and philosophy (catholicism, atheism, christianity, judaism, etc..)\n",
    "- trueatheism, truechristian, brokehugs, reformed, atheism, mormon, latterdaysaints, debateanatheist, academicbiblical, magicskyfairy, hinduism, standupshots, religion, debateachristian, islam, badphilosophy, philosophy, exjw, catholicism, mildredditdrama, judaism, exchristian, bad_religion, debatereligion, christianity, askphilosophy, exmormon, modelusgovverify, exmuslim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Community #10 (size = 48): gaming, electronics, gifts (randomactsofgaming, gamedeals, gamesale, etc..)\n",
    "- patientgamers, washingtondc, giftcardexchange, pkmntcgreferences, randomactsofgaming, comcast, electronic_cigarette, redditbay, phoenix, random_acts_of_pizza, randomkindness, gamedeals, sacramento, dogs, giftofgames, shouldibuythisgame, mushroomkingdom, santaslittlehelpers, subredditads, cats, gamedealsmeta, gamecollecting, dogtraining, badkarma, nova, xcom, connecticut, borrow, randomactsofpizza, diy_ejuice, totalwar, golf, gamesale, tropicalweather, homeless, freebies, assistance, baltimore, randomactsofchristmas, orlando, trade, newjersey, askvet, atlanta, randomactsofcards, ecigclassifieds, pets, pittsburgh\n",
    "- dogs and cats for some reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Community #0 (size = 99): mental illness, psychology, advice, relationships\n",
    "- mental illness: ocd, suicidewatch, bipolarreddit\n",
    "- relationships: relationships, divorce, dating_advice\n",
    "- advice: needadvice, legaladvice, askwomenadvice\n",
    "\n",
    "- bipolarreddit, justnomil, ocd, foreveralone, suicidewatch, needafriend, trueoffmychest, personalfinancecanada, socialanxiety, askcarsales, stocks, exnocontact, legaladviceofftopic, decidingtobebetter, polyamory, dating_advice, bisexual, amitheasshole, amiugly, schizophrenia, legal, financialindependence, askleo, sanctionedsuicide, brdapublic, roadcam, relationships, mentalhealth, gaybros, infertility, advice, divorce, mmfb, askdocs, neuro, raisedbynarcissists, aspergers, insurance, babybumps, prorevenge, bpd, psychology, college, sex, bipolar, realestate, pettyrevenge, actuallesbians, depression, tryingforababy, weddingplanning, childfree, beyondthebump, legaladviceuk, lgbt, teachers, medical, anxiety, diabetes, getting_over_it, askwomenadvice, wallstreetbets, autism, bestoflegaladvice, malehairadvice, daddit, scams, parenting, socialskills, churning, sexover30, universityofreddit, confession, relationship_advice, needadvice, chronicpain, abuseinterrupted, ptsd, lgbteens, askpsychology, longdistance, nursing, hawaii, breakingmom, offmychest, investing, askacademia, adhd, gradschool, ontario, personalfinance, selfharm, legaladvice, engineeringstudents, howtonotgiveafuck, dentistry, askgaybros, teenagers, psychiatry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Community #57, #56 (size = 1) lordsofminecraft, smutbuddy\n",
    "- A marketplace for selling minecraft items?\n",
    "- This subreddit does not have any significant links to other subreddits on the site, meaning users who post here don't interact much with users outside of the community?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smutbuddy\n"
     ]
    }
   ],
   "source": [
    "print (', '.join(list(communities[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add community property to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in range(len(communities)):\n",
    "    community = communities[index]\n",
    "    for subreddit in community:\n",
    "        G.nodes[subreddit]['community'] = str(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('leagueoflegends', {'community': '4'}), ('nfl', {'community': '15'}), ('cfb', {'community': '23'}), ('soccer', {'community': '33'}), ('dogemarket', {'community': '8'}), ('dogecoin', {'community': '8'}), ('gfycat', {'community': '33'}), ('india', {'community': '14'}), ('playmygame', {'community': '1'}), ('gamedev', {'community': '1'})]\n"
     ]
    }
   ],
   "source": [
    "print (list(G.nodes(data=True))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_wic = list(nx.within_inter_cluster(G, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions (positive links) 8533\n"
     ]
    }
   ],
   "source": [
    "print ('Number of predictions (positive links) {0}'.format(len(predicted_wic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "test_negative = []\n",
    "for i in range(len(test)):\n",
    "    n1 = random.sample(G.nodes(), 1)[0]\n",
    "    n2 = random.sample(G.nodes(), 1)[0]\n",
    "    \n",
    "    while (G.has_edge(n1, n2)):\n",
    "        n1 = random.sample(G.nodes(), 1)[0]\n",
    "        n2 = random.sample(G.nodes(), 1)[0]\n",
    "\n",
    "    test_negative.append((n1, n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_wic_negative = list(nx.within_inter_cluster(G, test_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctly-predicted links\n",
    "- 'buccaneers', 'greenbaypackers', 16000\n",
    "- 'cardinals', 'nationals', 3000\n",
    "- 'entp', 'mbti', 3000\n",
    "- 'exchristian', 'debateanatheist', 2000\n",
    "- 'pokemontrades', 'pokemonplaza', 2000\n",
    "\n",
    "### Links that were missed\n",
    "- 'offmychest', 'unpopularopinion', 0\n",
    "- 'subredditdrama', 'vegetarian', 0\n",
    "- 'dataisbeautiful', 'bestofoutrageculture', 0\n",
    "- 'mechanicalkeyboards', 'hardware', 0\n",
    "\n",
    "### Links that were often missed were from more niche, less popular subreddits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "ground_truth = ([1] * len(test)) + ([0] * len(test))\n",
    "print (sum(ground_truth) / len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for wic in predicted_wic:\n",
    "    if wic[-1] > 0:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)\n",
    "        \n",
    "for wic in predicted_wic_negative:\n",
    "    if wic[-1] > 0:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8399,  134],\n",
       "       [7238, 1295]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.imshow(confusion_matrix(ground_truth, preds), cmap=\"YlGnBu\")\n",
    "confusion_matrix(ground_truth, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall = ability of classifier to predict actual links\n",
    "- Recall = 0.5371 -> not very good at predicting future links (moderate-to-low recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5371234891603248\n"
     ]
    }
   ],
   "source": [
    "recall = 8399.0 / (8399.0 + 7238.0)\n",
    "print (recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision = ability of classifier to avoid false positives\n",
    "- Precision = 0.98 -> very good, when the classifier says a link doesn't exist it probably doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9842962615727177\n"
     ]
    }
   ],
   "source": [
    "precision = 8399.0 / (8399.0 + 134.0)\n",
    "print (precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- Lower community resolution led to better accuracy in link prediction but more undefined communities\n",
    "    - 32.6% with R = 1 and 11% with R = 3\n",
    "- Less culling led to slightly higher accuracy but not much, and was much slower to calculate\n",
    "    - Degree >= 5, R = 1 -> 39.74% acc\n",
    "    - Degree >= 25, R = 1 -> 32.6% acc\n",
    "- Discarding edge weights when detectecting communities also had a slightly higher accuracy\n",
    "    - weighted edges, R = 3 -> 11%\n",
    "    - non-weighted edges, R = 3 -> 14.7%\n",
    "    \n",
    "- A lot more difficult to correcly predict new links, the classifier was much better at avoiding false positives. Community-based detection was moderately good at finding new links but had a much higher precision, meaning it was much more likely to avoid recommending a subreddit that isn't related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
